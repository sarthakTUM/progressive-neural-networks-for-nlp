{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spans(txt):\n",
    "    tokens=word_tokenize(txt)\n",
    "    offset = 0\n",
    "    for token in tokens:\n",
    "        offset = txt.find(token, offset)\n",
    "        yield token, offset, offset+len(token)\n",
    "        offset += len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../resources/data/NER/dfki_product/test.json'\n",
    "json_recs = []\n",
    "with open(file_path, encoding='utf8') as f:\n",
    "    # Variable for building our JSON block\n",
    "    json_block = []\n",
    "\n",
    "    for line in f:\n",
    "\n",
    "        # Add the line to our JSON block\n",
    "        json_block.append(line)\n",
    "\n",
    "        # Check whether we closed our JSON block\n",
    "        if line.startswith('}'):\n",
    "\n",
    "            # Do something with the JSON dictionary\n",
    "            json_dict = json.loads(''.join(json_block))\n",
    "            #pprint(json_dict)\n",
    "            json_recs.append(json_dict)\n",
    "            # Start a new block\n",
    "            json_block = []\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing json_idx: 0\n",
      "processing json_idx: 1\n",
      "processing json_idx: 2\n",
      "processing json_idx: 3\n",
      "processing json_idx: 4\n",
      "processing json_idx: 5\n",
      "processing json_idx: 6\n",
      "processing json_idx: 7\n",
      "processing json_idx: 8\n",
      "processing json_idx: 9\n",
      "processing json_idx: 10\n",
      "processing json_idx: 11\n",
      "processing json_idx: 12\n",
      "processing json_idx: 13\n",
      "processing json_idx: 14\n",
      "processing json_idx: 15\n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "processing json_idx: 16\n",
      "processing json_idx: 17\n",
      "processing json_idx: 18\n",
      "processing json_idx: 19\n",
      "processing json_idx: 20\n",
      "processing json_idx: 21\n",
      "processing json_idx: 22\n",
      "processing json_idx: 23\n",
      "processing json_idx: 24\n",
      "processing json_idx: 25\n",
      "processing json_idx: 26\n",
      "processing json_idx: 27\n",
      "processing json_idx: 28\n",
      "processing json_idx: 29\n",
      "processing json_idx: 30\n",
      "processing json_idx: 31\n",
      "processing json_idx: 32\n",
      "processing json_idx: 33\n",
      "processing json_idx: 34\n",
      "processing json_idx: 35\n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "processing json_idx: 36\n",
      "processing json_idx: 37\n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "processing json_idx: 38\n",
      "processing json_idx: 39\n",
      "processing json_idx: 40\n",
      "processing json_idx: 41\n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "processing json_idx: 42\n",
      "processing json_idx: 43\n",
      "processing json_idx: 44\n",
      "processing json_idx: 45\n",
      "processing json_idx: 46\n",
      "processing json_idx: 47\n",
      "processing json_idx: 48\n",
      "processing json_idx: 49\n",
      "processing json_idx: 50\n",
      "processing json_idx: 51\n",
      "processing json_idx: 52\n",
      "processing json_idx: 53\n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "tokenized:  `` token in sentence:  \n",
      "tokenized:  '' token in sentence:  \n",
      "processing json_idx: 54\n",
      "processing json_idx: 55\n",
      "processing json_idx: 56\n",
      "processing json_idx: 57\n",
      "processing json_idx: 58\n",
      "processing json_idx: 59\n",
      "processing json_idx: 60\n",
      "processing json_idx: 61\n",
      "processing json_idx: 62\n",
      "processing json_idx: 63\n",
      "processing json_idx: 64\n",
      "processing json_idx: 65\n",
      "processing json_idx: 66\n",
      "processing json_idx: 67\n",
      "processing json_idx: 68\n",
      "processing json_idx: 69\n",
      "processing json_idx: 70\n",
      "processing json_idx: 71\n",
      "processing json_idx: 72\n",
      "processing json_idx: 73\n",
      "processing json_idx: 74\n",
      "processing json_idx: 75\n",
      "processing json_idx: 76\n",
      "processing json_idx: 77\n",
      "processing json_idx: 78\n",
      "processing json_idx: 79\n",
      "processing json_idx: 80\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for json_rec_idx, json_rec in enumerate(json_recs):\n",
    "    print('processing json_idx: {}'.format(json_rec_idx))\n",
    "    for sent_idx, s in enumerate(sent_tokenize(json_rec['text']['string'])):\n",
    "        sentence = []\n",
    "        for token in spans(s):\n",
    "            if not token[0]==s[token[1]:token[2]]:\n",
    "                print('tokenized: ', token[0], 'token in sentence: ', s[token[1]:token[2]])\n",
    "                \n",
    "            for concept in json_rec['conceptMentions']['array']:\n",
    "                start = concept['span']['start']\n",
    "                end = concept['span']['end']\n",
    "                # word can be start of the concept\n",
    "                if token[1] == start and token[2] < end:\n",
    "                    sentence.append((token[0], 'B-'+concept['type']))\n",
    "                # word can be the concept\n",
    "                elif token[1] == start and token[2] == end:\n",
    "                    sentence.append((token[0], 'B-'+concept['type']))\n",
    "                # word can be inside concept\n",
    "                elif token[1] > start and token[2] < end:\n",
    "                    sentence.append((token[0], 'I-'+concept['type']))\n",
    "                # word can be last of concept\n",
    "                elif token[1] > start and token[2] == end:\n",
    "                    sentence.append((token[0], 'I-'+concept['type']))\n",
    "                # word not in span\n",
    "                else:\n",
    "                    sentence.append((token[0], 'O'))\n",
    "        sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2094"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'string': 'PM Modi with President of Russia, Vladimir Putin, St. Petersburg, Russia, June 01, 2017\\nSaint-Petersburg Declaration By the Russian Federation And the Republic Of India:\\xa0A Vision For The 21st Century\\nJune 01, 2017\\n\\xa0\\n(Excerpts on India-Russia Civil Nuclear Cooperation)\\nCooperation in the peaceful uses of nuclear energy has emerged as one of the hallmarks of the strategic partnership between the two countries, contributing to India’s energy security and energizing broader scientific and technological cooperation. With concerted efforts on both sides, there has been a series of steady and demonstrable achievements in our civil nuclear partnership, including advancing nuclear power projects at the Kudankulam site and transforming it into one of India’s largest energy hubs. We welcome the conclusion of the General Framework Agreement and Credit Protocol for Units 5 and 6 of the Kudankulam Nuclear Power Plant. We will work towards the implementation of the Strategic Vision for Strengthening Cooperation in Peaceful Uses of Atomic Energy signed between the two countries on December 11, 2014. The future of Indian-Russian cooperation holds great promise across a wide spectrum covering nuclear power, nuclear fuel cycle and nuclear science and technology.\\n\\xa0\\nThe growing partnership in the nuclear power sector between India and Russia has opened opportunities for developing advanced nuclear manufacturing capabilities in India in line with Government of India’s \"Make in India” initiative. India and Russia commit themselves to earnestly implement the \"Programme of Action for Localization in India” signed on 24 December 2015, and to encourage their nuclear industries to engage closely and foster concrete collaborations.\\n\\xa0\\n\\n'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_recs[56]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PM Modi with President of Russia, Vladimir Putin, St. Petersburg, Russia, June 01, 2017\n",
      "Saint-Petersburg Declaration By the Russian Federation And the Republic Of India: A Vision For The 21st Century\n",
      "June 01, 2017\n",
      " \n",
      "(Excerpts on India-Russia Civil Nuclear Cooperation)\n",
      "Cooperation in the peaceful uses of nuclear energy has emerged as one of the hallmarks of the strategic partnership between the two countries, contributing to India’s energy security and energizing broader scientific and technological cooperation.\n",
      "1 With concerted efforts on both sides, there has been a series of steady and demonstrable achievements in our civil nuclear partnership, including advancing nuclear power projects at the Kudankulam site and transforming it into one of India’s largest energy hubs.\n",
      "2 We welcome the conclusion of the General Framework Agreement and Credit Protocol for Units 5 and 6 of the Kudankulam Nuclear Power Plant.\n",
      "3 We will work towards the implementation of the Strategic Vision for Strengthening Cooperation in Peaceful Uses of Atomic Energy signed between the two countries on December 11, 2014.\n",
      "4 The future of Indian-Russian cooperation holds great promise across a wide spectrum covering nuclear power, nuclear fuel cycle and nuclear science and technology.\n",
      "5 The growing partnership in the nuclear power sector between India and Russia has opened opportunities for developing advanced nuclear manufacturing capabilities in India in line with Government of India’s \"Make in India” initiative.\n",
      "6 India and Russia commit themselves to earnestly implement the \"Programme of Action for Localization in India” signed on 24 December 2015, and to encourage their nuclear industries to engage closely and foster concrete collaborations.\n"
     ]
    }
   ],
   "source": [
    "for sent_idx, sent in enumerate(sent_tokenize(json_recs[56]['text']['string'])):\n",
    "    print(sent_idx, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Home > Blogs > T&D World's The Briefing Room > Sentient Energy Announces Release of Ample Analytics 3.0 to Identify Distribution Grid faults and Potential Equipment Failures Sentient Energy Announces Release of Ample Analytics 3.0 to Identify Distribution Grid faults and Potential Equipment Failures Feb 4, 2016 by Amy Fischbach in T&D World's The Briefing Room Sentient Energy, Inc. announced the release of its Ample 3.0 Analytics platform. Burlingame, Calif., February 4, 2016 – Sentient Energy, Inc., a leading provider of advanced grid monitoring and analytics solutions for electric utilities, today announced the release of its Ample™ 3.0 Analytics platform. When paired with Sentient Energy's family of intelligent line sensors, the Ample Analytics platform provides everything needed to manage and analyze the immense amount of data captured by Sentient MM3 ™ sensors when deployed on the distribution grid. Ample can also serve as the data integration platform for SCADA and DMS. MM3 line sensors feature Sentient Energy's proprietary waveform analysis technology that captures high-resolution oscillography associated with faults and network events anywhere on the distribution grid and wirelessly transmits key data or the entire waveform, as needed, to the Ample Analytics platform for further analysis. Once this waveform data is collected, catalogued, and analyzed, it is possible to identify an event and its immediate cause -- such as vegetation, lightning, or animal intrusion. It is also possible to identify many underlying conditions that lead to failure, such as deteriorating connections or faulty equipment. The Ample Analytics platform is a vital component of our comprehensive Grid Analytics System . Together, Sentient Energy intelligent sensors and Ample Analytics platform hold the key to accurately predicting future grid equipment failures and preventing outages before they occur, said Sentient Energy CEO, Jim Keener. We are confident this technology will lead to a significantly more resilient grid and a major reduction in service interruptions. Ample Analytics 3.0 has been deployed by Florida Power & Light (FPL) as part of the utility's 20,000 MM3 sensor project covering its entire 42,000-mile overhead service territory. This is believed to be the largest distribution grid sensor deployment in the world ( see press release ). FPL will use Sentient Energy's Grid Analytics System – MM3 sensors, high-resolution oscillography, and the Ample Analytics platform – to detect minute disturbances on the grid and use this information to isolate faults, detect defective equipment before it fails, and analyze the unique patterns of these events to predict the likelihood of future outages. Sentient Energy will showcase Ample Analytics 3.0. along with its MM3 intelligent sensors, and high-resolution waveform analysis at DistribuTECH 2016 – booth #849. About Sentient Energy, Inc. Sentient Energy makes power delivery safe, reliable and solar ready. We provide the industry's only Grid Analytics System that covers the entire distribution network with quickly deployed intelligent sensors and analytics that identify and analyze potential faults and other grid events. We lead the market with the largest mesh network line sensor deployments in North America, and partnerships with leading utility network providers including Silver Spring Networks, Landis + Gyr, and AT&T. For more information, visit www.sentient-energy.com . CONTACT: John Easton 904-415-6266 jeason@sentient-energy.com Discuss this Blog Entry 0\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict['text']['string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sgupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Home', 0, 4)\n",
      "('>', 5, 6)\n",
      "('Blogs', 7, 12)\n",
      "('>', 13, 14)\n",
      "('T', 15, 16)\n",
      "('&', 16, 17)\n",
      "('D', 17, 18)\n",
      "('World', 19, 24)\n",
      "(\"'s\", 24, 26)\n",
      "('The', 27, 30)\n",
      "('Briefing', 31, 39)\n",
      "('Room', 40, 44)\n",
      "('>', 45, 46)\n",
      "('Sentient', 47, 55)\n",
      "('Energy', 56, 62)\n",
      "('Announces', 63, 72)\n",
      "('Release', 73, 80)\n",
      "('of', 81, 83)\n",
      "('Ample', 84, 89)\n",
      "('Analytics', 90, 99)\n",
      "('3.0', 100, 103)\n",
      "('to', 104, 106)\n",
      "('Identify', 107, 115)\n",
      "('Distribution', 116, 128)\n",
      "('Grid', 129, 133)\n",
      "('faults', 134, 140)\n",
      "('and', 141, 144)\n",
      "('Potential', 145, 154)\n",
      "('Equipment', 155, 164)\n",
      "('Failures', 165, 173)\n",
      "('Sentient', 174, 182)\n",
      "('Energy', 183, 189)\n",
      "('Announces', 190, 199)\n",
      "('Release', 200, 207)\n",
      "('of', 208, 210)\n",
      "('Ample', 211, 216)\n",
      "('Analytics', 217, 226)\n",
      "('3.0', 227, 230)\n",
      "('to', 231, 233)\n",
      "('Identify', 234, 242)\n",
      "('Distribution', 243, 255)\n",
      "('Grid', 256, 260)\n",
      "('faults', 261, 267)\n",
      "('and', 268, 271)\n",
      "('Potential', 272, 281)\n",
      "('Equipment', 282, 291)\n",
      "('Failures', 292, 300)\n",
      "('Feb', 301, 304)\n",
      "('4', 305, 306)\n",
      "(',', 306, 307)\n",
      "('2016', 308, 312)\n",
      "('by', 313, 315)\n",
      "('Amy', 316, 319)\n",
      "('Fischbach', 320, 329)\n",
      "('in', 330, 332)\n",
      "('T', 333, 334)\n",
      "('&', 334, 335)\n",
      "('D', 335, 336)\n",
      "('World', 337, 342)\n",
      "(\"'s\", 342, 344)\n",
      "('The', 345, 348)\n",
      "('Briefing', 349, 357)\n",
      "('Room', 358, 362)\n",
      "('Sentient', 363, 371)\n",
      "('Energy', 372, 378)\n",
      "(',', 378, 379)\n",
      "('Inc.', 380, 384)\n",
      "('announced', 385, 394)\n",
      "('the', 395, 398)\n",
      "('release', 399, 406)\n",
      "('of', 407, 409)\n",
      "('its', 410, 413)\n",
      "('Ample', 414, 419)\n",
      "('3.0', 420, 423)\n",
      "('Analytics', 424, 433)\n",
      "('platform', 434, 442)\n",
      "('.', 442, 443)\n",
      "('Burlingame', 444, 454)\n",
      "(',', 454, 455)\n",
      "('Calif.', 456, 462)\n",
      "(',', 462, 463)\n",
      "('February', 464, 472)\n",
      "('4', 473, 474)\n",
      "(',', 474, 475)\n",
      "('2016', 476, 480)\n",
      "('–', 481, 482)\n",
      "('Sentient', 483, 491)\n",
      "('Energy', 492, 498)\n",
      "(',', 498, 499)\n",
      "('Inc.', 500, 504)\n",
      "(',', 504, 505)\n",
      "('a', 506, 507)\n",
      "('leading', 508, 515)\n",
      "('provider', 516, 524)\n",
      "('of', 525, 527)\n",
      "('advanced', 528, 536)\n",
      "('grid', 537, 541)\n",
      "('monitoring', 542, 552)\n",
      "('and', 553, 556)\n",
      "('analytics', 557, 566)\n",
      "('solutions', 567, 576)\n",
      "('for', 577, 580)\n",
      "('electric', 581, 589)\n",
      "('utilities', 590, 599)\n",
      "(',', 599, 600)\n",
      "('today', 601, 606)\n",
      "('announced', 607, 616)\n",
      "('the', 617, 620)\n",
      "('release', 621, 628)\n",
      "('of', 629, 631)\n",
      "('its', 632, 635)\n",
      "('Ample™', 636, 642)\n",
      "('3.0', 643, 646)\n",
      "('Analytics', 647, 656)\n",
      "('platform', 657, 665)\n",
      "('.', 665, 666)\n",
      "('When', 667, 671)\n",
      "('paired', 672, 678)\n",
      "('with', 679, 683)\n",
      "('Sentient', 684, 692)\n",
      "('Energy', 693, 699)\n",
      "(\"'s\", 699, 701)\n",
      "('family', 702, 708)\n",
      "('of', 709, 711)\n",
      "('intelligent', 712, 723)\n",
      "('line', 724, 728)\n",
      "('sensors', 729, 736)\n",
      "(',', 736, 737)\n",
      "('the', 738, 741)\n",
      "('Ample', 742, 747)\n",
      "('Analytics', 748, 757)\n",
      "('platform', 758, 766)\n",
      "('provides', 767, 775)\n",
      "('everything', 776, 786)\n",
      "('needed', 787, 793)\n",
      "('to', 794, 796)\n",
      "('manage', 797, 803)\n",
      "('and', 804, 807)\n",
      "('analyze', 808, 815)\n",
      "('the', 816, 819)\n",
      "('immense', 820, 827)\n",
      "('amount', 828, 834)\n",
      "('of', 835, 837)\n",
      "('data', 838, 842)\n",
      "('captured', 843, 851)\n",
      "('by', 852, 854)\n",
      "('Sentient', 855, 863)\n",
      "('MM3', 864, 867)\n",
      "('™', 868, 869)\n",
      "('sensors', 870, 877)\n",
      "('when', 878, 882)\n",
      "('deployed', 883, 891)\n",
      "('on', 892, 894)\n",
      "('the', 895, 898)\n",
      "('distribution', 899, 911)\n",
      "('grid', 912, 916)\n",
      "('.', 916, 917)\n",
      "('Ample', 918, 923)\n",
      "('can', 924, 927)\n",
      "('also', 928, 932)\n",
      "('serve', 933, 938)\n",
      "('as', 939, 941)\n",
      "('the', 942, 945)\n",
      "('data', 946, 950)\n",
      "('integration', 951, 962)\n",
      "('platform', 963, 971)\n",
      "('for', 972, 975)\n",
      "('SCADA', 976, 981)\n",
      "('and', 982, 985)\n",
      "('DMS', 986, 989)\n",
      "('.', 989, 990)\n",
      "('MM3', 991, 994)\n",
      "('line', 995, 999)\n",
      "('sensors', 1000, 1007)\n",
      "('feature', 1008, 1015)\n",
      "('Sentient', 1016, 1024)\n",
      "('Energy', 1025, 1031)\n",
      "(\"'s\", 1031, 1033)\n",
      "('proprietary', 1034, 1045)\n",
      "('waveform', 1046, 1054)\n",
      "('analysis', 1055, 1063)\n",
      "('technology', 1064, 1074)\n",
      "('that', 1075, 1079)\n",
      "('captures', 1080, 1088)\n",
      "('high-resolution', 1089, 1104)\n",
      "('oscillography', 1105, 1118)\n",
      "('associated', 1119, 1129)\n",
      "('with', 1130, 1134)\n",
      "('faults', 1135, 1141)\n",
      "('and', 1142, 1145)\n",
      "('network', 1146, 1153)\n",
      "('events', 1154, 1160)\n",
      "('anywhere', 1161, 1169)\n",
      "('on', 1170, 1172)\n",
      "('the', 1173, 1176)\n",
      "('distribution', 1177, 1189)\n",
      "('grid', 1190, 1194)\n",
      "('and', 1195, 1198)\n",
      "('wirelessly', 1199, 1209)\n",
      "('transmits', 1210, 1219)\n",
      "('key', 1220, 1223)\n",
      "('data', 1224, 1228)\n",
      "('or', 1229, 1231)\n",
      "('the', 1232, 1235)\n",
      "('entire', 1236, 1242)\n",
      "('waveform', 1243, 1251)\n",
      "(',', 1251, 1252)\n",
      "('as', 1253, 1255)\n",
      "('needed', 1256, 1262)\n",
      "(',', 1262, 1263)\n",
      "('to', 1264, 1266)\n",
      "('the', 1267, 1270)\n",
      "('Ample', 1271, 1276)\n",
      "('Analytics', 1277, 1286)\n",
      "('platform', 1287, 1295)\n",
      "('for', 1296, 1299)\n",
      "('further', 1300, 1307)\n",
      "('analysis', 1308, 1316)\n",
      "('.', 1316, 1317)\n",
      "('Once', 1318, 1322)\n",
      "('this', 1323, 1327)\n",
      "('waveform', 1328, 1336)\n",
      "('data', 1337, 1341)\n",
      "('is', 1342, 1344)\n",
      "('collected', 1345, 1354)\n",
      "(',', 1354, 1355)\n",
      "('catalogued', 1356, 1366)\n",
      "(',', 1366, 1367)\n",
      "('and', 1368, 1371)\n",
      "('analyzed', 1372, 1380)\n",
      "(',', 1380, 1381)\n",
      "('it', 1382, 1384)\n",
      "('is', 1385, 1387)\n",
      "('possible', 1388, 1396)\n",
      "('to', 1397, 1399)\n",
      "('identify', 1400, 1408)\n",
      "('an', 1409, 1411)\n",
      "('event', 1412, 1417)\n",
      "('and', 1418, 1421)\n",
      "('its', 1422, 1425)\n",
      "('immediate', 1426, 1435)\n",
      "('cause', 1436, 1441)\n",
      "('--', 1442, 1444)\n",
      "('such', 1445, 1449)\n",
      "('as', 1450, 1452)\n",
      "('vegetation', 1453, 1463)\n",
      "(',', 1463, 1464)\n",
      "('lightning', 1465, 1474)\n",
      "(',', 1474, 1475)\n",
      "('or', 1476, 1478)\n",
      "('animal', 1479, 1485)\n",
      "('intrusion', 1486, 1495)\n",
      "('.', 1495, 1496)\n",
      "('It', 1497, 1499)\n",
      "('is', 1500, 1502)\n",
      "('also', 1503, 1507)\n",
      "('possible', 1508, 1516)\n",
      "('to', 1517, 1519)\n",
      "('identify', 1520, 1528)\n",
      "('many', 1529, 1533)\n",
      "('underlying', 1534, 1544)\n",
      "('conditions', 1545, 1555)\n",
      "('that', 1556, 1560)\n",
      "('lead', 1561, 1565)\n",
      "('to', 1566, 1568)\n",
      "('failure', 1569, 1576)\n",
      "(',', 1576, 1577)\n",
      "('such', 1578, 1582)\n",
      "('as', 1583, 1585)\n",
      "('deteriorating', 1586, 1599)\n",
      "('connections', 1600, 1611)\n",
      "('or', 1612, 1614)\n",
      "('faulty', 1615, 1621)\n",
      "('equipment', 1622, 1631)\n",
      "('.', 1631, 1632)\n",
      "('The', 1633, 1636)\n",
      "('Ample', 1637, 1642)\n",
      "('Analytics', 1643, 1652)\n",
      "('platform', 1653, 1661)\n",
      "('is', 1662, 1664)\n",
      "('a', 1665, 1666)\n",
      "('vital', 1667, 1672)\n",
      "('component', 1673, 1682)\n",
      "('of', 1683, 1685)\n",
      "('our', 1686, 1689)\n",
      "('comprehensive', 1690, 1703)\n",
      "('Grid', 1704, 1708)\n",
      "('Analytics', 1709, 1718)\n",
      "('System', 1719, 1725)\n",
      "('.', 1726, 1727)\n",
      "('Together', 1728, 1736)\n",
      "(',', 1736, 1737)\n",
      "('Sentient', 1738, 1746)\n",
      "('Energy', 1747, 1753)\n",
      "('intelligent', 1754, 1765)\n",
      "('sensors', 1766, 1773)\n",
      "('and', 1774, 1777)\n",
      "('Ample', 1778, 1783)\n",
      "('Analytics', 1784, 1793)\n",
      "('platform', 1794, 1802)\n",
      "('hold', 1803, 1807)\n",
      "('the', 1808, 1811)\n",
      "('key', 1812, 1815)\n",
      "('to', 1816, 1818)\n",
      "('accurately', 1819, 1829)\n",
      "('predicting', 1830, 1840)\n",
      "('future', 1841, 1847)\n",
      "('grid', 1848, 1852)\n",
      "('equipment', 1853, 1862)\n",
      "('failures', 1863, 1871)\n",
      "('and', 1872, 1875)\n",
      "('preventing', 1876, 1886)\n",
      "('outages', 1887, 1894)\n",
      "('before', 1895, 1901)\n",
      "('they', 1902, 1906)\n",
      "('occur', 1907, 1912)\n",
      "(',', 1912, 1913)\n",
      "('said', 1914, 1918)\n",
      "('Sentient', 1919, 1927)\n",
      "('Energy', 1928, 1934)\n",
      "('CEO', 1935, 1938)\n",
      "(',', 1938, 1939)\n",
      "('Jim', 1940, 1943)\n",
      "('Keener', 1944, 1950)\n",
      "('.', 1950, 1951)\n",
      "('We', 1952, 1954)\n",
      "('are', 1955, 1958)\n",
      "('confident', 1959, 1968)\n",
      "('this', 1969, 1973)\n",
      "('technology', 1974, 1984)\n",
      "('will', 1985, 1989)\n",
      "('lead', 1990, 1994)\n",
      "('to', 1995, 1997)\n",
      "('a', 1998, 1999)\n",
      "('significantly', 2000, 2013)\n",
      "('more', 2014, 2018)\n",
      "('resilient', 2019, 2028)\n",
      "('grid', 2029, 2033)\n",
      "('and', 2034, 2037)\n",
      "('a', 2038, 2039)\n",
      "('major', 2040, 2045)\n",
      "('reduction', 2046, 2055)\n",
      "('in', 2056, 2058)\n",
      "('service', 2059, 2066)\n",
      "('interruptions', 2067, 2080)\n",
      "('.', 2080, 2081)\n",
      "('Ample', 2082, 2087)\n",
      "('Analytics', 2088, 2097)\n",
      "('3.0', 2098, 2101)\n",
      "('has', 2102, 2105)\n",
      "('been', 2106, 2110)\n",
      "('deployed', 2111, 2119)\n",
      "('by', 2120, 2122)\n",
      "('Florida', 2123, 2130)\n",
      "('Power', 2131, 2136)\n",
      "('&', 2137, 2138)\n",
      "('Light', 2139, 2144)\n",
      "('(', 2145, 2146)\n",
      "('FPL', 2146, 2149)\n",
      "(')', 2149, 2150)\n",
      "('as', 2151, 2153)\n",
      "('part', 2154, 2158)\n",
      "('of', 2159, 2161)\n",
      "('the', 2162, 2165)\n",
      "('utility', 2166, 2173)\n",
      "(\"'s\", 2173, 2175)\n",
      "('20,000', 2176, 2182)\n",
      "('MM3', 2183, 2186)\n",
      "('sensor', 2187, 2193)\n",
      "('project', 2194, 2201)\n",
      "('covering', 2202, 2210)\n",
      "('its', 2211, 2214)\n",
      "('entire', 2215, 2221)\n",
      "('42,000-mile', 2222, 2233)\n",
      "('overhead', 2234, 2242)\n",
      "('service', 2243, 2250)\n",
      "('territory', 2251, 2260)\n",
      "('.', 2260, 2261)\n",
      "('This', 2262, 2266)\n",
      "('is', 2267, 2269)\n",
      "('believed', 2270, 2278)\n",
      "('to', 2279, 2281)\n",
      "('be', 2282, 2284)\n",
      "('the', 2285, 2288)\n",
      "('largest', 2289, 2296)\n",
      "('distribution', 2297, 2309)\n",
      "('grid', 2310, 2314)\n",
      "('sensor', 2315, 2321)\n",
      "('deployment', 2322, 2332)\n",
      "('in', 2333, 2335)\n",
      "('the', 2336, 2339)\n",
      "('world', 2340, 2345)\n",
      "('(', 2346, 2347)\n",
      "('see', 2348, 2351)\n",
      "('press', 2352, 2357)\n",
      "('release', 2358, 2365)\n",
      "(')', 2366, 2367)\n",
      "('.', 2367, 2368)\n",
      "('FPL', 2369, 2372)\n",
      "('will', 2373, 2377)\n",
      "('use', 2378, 2381)\n",
      "('Sentient', 2382, 2390)\n",
      "('Energy', 2391, 2397)\n",
      "(\"'s\", 2397, 2399)\n",
      "('Grid', 2400, 2404)\n",
      "('Analytics', 2405, 2414)\n",
      "('System', 2415, 2421)\n",
      "('–', 2422, 2423)\n",
      "('MM3', 2424, 2427)\n",
      "('sensors', 2428, 2435)\n",
      "(',', 2435, 2436)\n",
      "('high-resolution', 2437, 2452)\n",
      "('oscillography', 2453, 2466)\n",
      "(',', 2466, 2467)\n",
      "('and', 2468, 2471)\n",
      "('the', 2472, 2475)\n",
      "('Ample', 2476, 2481)\n",
      "('Analytics', 2482, 2491)\n",
      "('platform', 2492, 2500)\n",
      "('–', 2501, 2502)\n",
      "('to', 2503, 2505)\n",
      "('detect', 2506, 2512)\n",
      "('minute', 2513, 2519)\n",
      "('disturbances', 2520, 2532)\n",
      "('on', 2533, 2535)\n",
      "('the', 2536, 2539)\n",
      "('grid', 2540, 2544)\n",
      "('and', 2545, 2548)\n",
      "('use', 2549, 2552)\n",
      "('this', 2553, 2557)\n",
      "('information', 2558, 2569)\n",
      "('to', 2570, 2572)\n",
      "('isolate', 2573, 2580)\n",
      "('faults', 2581, 2587)\n",
      "(',', 2587, 2588)\n",
      "('detect', 2589, 2595)\n",
      "('defective', 2596, 2605)\n",
      "('equipment', 2606, 2615)\n",
      "('before', 2616, 2622)\n",
      "('it', 2623, 2625)\n",
      "('fails', 2626, 2631)\n",
      "(',', 2631, 2632)\n",
      "('and', 2633, 2636)\n",
      "('analyze', 2637, 2644)\n",
      "('the', 2645, 2648)\n",
      "('unique', 2649, 2655)\n",
      "('patterns', 2656, 2664)\n",
      "('of', 2665, 2667)\n",
      "('these', 2668, 2673)\n",
      "('events', 2674, 2680)\n",
      "('to', 2681, 2683)\n",
      "('predict', 2684, 2691)\n",
      "('the', 2692, 2695)\n",
      "('likelihood', 2696, 2706)\n",
      "('of', 2707, 2709)\n",
      "('future', 2710, 2716)\n",
      "('outages', 2717, 2724)\n",
      "('.', 2724, 2725)\n",
      "('Sentient', 2726, 2734)\n",
      "('Energy', 2735, 2741)\n",
      "('will', 2742, 2746)\n",
      "('showcase', 2747, 2755)\n",
      "('Ample', 2756, 2761)\n",
      "('Analytics', 2762, 2771)\n",
      "('3.0.', 2772, 2776)\n",
      "('along', 2777, 2782)\n",
      "('with', 2783, 2787)\n",
      "('its', 2788, 2791)\n",
      "('MM3', 2792, 2795)\n",
      "('intelligent', 2796, 2807)\n",
      "('sensors', 2808, 2815)\n",
      "(',', 2815, 2816)\n",
      "('and', 2817, 2820)\n",
      "('high-resolution', 2821, 2836)\n",
      "('waveform', 2837, 2845)\n",
      "('analysis', 2846, 2854)\n",
      "('at', 2855, 2857)\n",
      "('DistribuTECH', 2858, 2870)\n",
      "('2016', 2871, 2875)\n",
      "('–', 2876, 2877)\n",
      "('booth', 2878, 2883)\n",
      "('#', 2884, 2885)\n",
      "('849', 2885, 2888)\n",
      "('.', 2888, 2889)\n",
      "('About', 2890, 2895)\n",
      "('Sentient', 2896, 2904)\n",
      "('Energy', 2905, 2911)\n",
      "(',', 2911, 2912)\n",
      "('Inc.', 2913, 2917)\n",
      "('Sentient', 2918, 2926)\n",
      "('Energy', 2927, 2933)\n",
      "('makes', 2934, 2939)\n",
      "('power', 2940, 2945)\n",
      "('delivery', 2946, 2954)\n",
      "('safe', 2955, 2959)\n",
      "(',', 2959, 2960)\n",
      "('reliable', 2961, 2969)\n",
      "('and', 2970, 2973)\n",
      "('solar', 2974, 2979)\n",
      "('ready', 2980, 2985)\n",
      "('.', 2985, 2986)\n",
      "('We', 2987, 2989)\n",
      "('provide', 2990, 2997)\n",
      "('the', 2998, 3001)\n",
      "('industry', 3002, 3010)\n",
      "(\"'s\", 3010, 3012)\n",
      "('only', 3013, 3017)\n",
      "('Grid', 3018, 3022)\n",
      "('Analytics', 3023, 3032)\n",
      "('System', 3033, 3039)\n",
      "('that', 3040, 3044)\n",
      "('covers', 3045, 3051)\n",
      "('the', 3052, 3055)\n",
      "('entire', 3056, 3062)\n",
      "('distribution', 3063, 3075)\n",
      "('network', 3076, 3083)\n",
      "('with', 3084, 3088)\n",
      "('quickly', 3089, 3096)\n",
      "('deployed', 3097, 3105)\n",
      "('intelligent', 3106, 3117)\n",
      "('sensors', 3118, 3125)\n",
      "('and', 3126, 3129)\n",
      "('analytics', 3130, 3139)\n",
      "('that', 3140, 3144)\n",
      "('identify', 3145, 3153)\n",
      "('and', 3154, 3157)\n",
      "('analyze', 3158, 3165)\n",
      "('potential', 3166, 3175)\n",
      "('faults', 3176, 3182)\n",
      "('and', 3183, 3186)\n",
      "('other', 3187, 3192)\n",
      "('grid', 3193, 3197)\n",
      "('events', 3198, 3204)\n",
      "('.', 3204, 3205)\n",
      "('We', 3206, 3208)\n",
      "('lead', 3209, 3213)\n",
      "('the', 3214, 3217)\n",
      "('market', 3218, 3224)\n",
      "('with', 3225, 3229)\n",
      "('the', 3230, 3233)\n",
      "('largest', 3234, 3241)\n",
      "('mesh', 3242, 3246)\n",
      "('network', 3247, 3254)\n",
      "('line', 3255, 3259)\n",
      "('sensor', 3260, 3266)\n",
      "('deployments', 3267, 3278)\n",
      "('in', 3279, 3281)\n",
      "('North', 3282, 3287)\n",
      "('America', 3288, 3295)\n",
      "(',', 3295, 3296)\n",
      "('and', 3297, 3300)\n",
      "('partnerships', 3301, 3313)\n",
      "('with', 3314, 3318)\n",
      "('leading', 3319, 3326)\n",
      "('utility', 3327, 3334)\n",
      "('network', 3335, 3342)\n",
      "('providers', 3343, 3352)\n",
      "('including', 3353, 3362)\n",
      "('Silver', 3363, 3369)\n",
      "('Spring', 3370, 3376)\n",
      "('Networks', 3377, 3385)\n",
      "(',', 3385, 3386)\n",
      "('Landis', 3387, 3393)\n",
      "('+', 3394, 3395)\n",
      "('Gyr', 3396, 3399)\n",
      "(',', 3399, 3400)\n",
      "('and', 3401, 3404)\n",
      "('AT', 3405, 3407)\n",
      "('&', 3407, 3408)\n",
      "('T', 3408, 3409)\n",
      "('.', 3409, 3410)\n",
      "('For', 3411, 3414)\n",
      "('more', 3415, 3419)\n",
      "('information', 3420, 3431)\n",
      "(',', 3431, 3432)\n",
      "('visit', 3433, 3438)\n",
      "('www.sentient-energy.com', 3439, 3462)\n",
      "('.', 3463, 3464)\n",
      "('CONTACT', 3465, 3472)\n",
      "(':', 3472, 3473)\n",
      "('John', 3474, 3478)\n",
      "('Easton', 3479, 3485)\n",
      "('904-415-6266', 3486, 3498)\n",
      "('jeason', 3499, 3505)\n",
      "('@', 3505, 3506)\n",
      "('sentient-energy.com', 3506, 3525)\n",
      "('Discuss', 3526, 3533)\n",
      "('this', 3534, 3538)\n",
      "('Blog', 3539, 3543)\n",
      "('Entry', 3544, 3549)\n",
      "('0', 3550, 3551)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "s = json_dict['text']['string']\n",
    "for token in spans(s):\n",
    "    print(token)\n",
    "    assert token[0]==s[token[1]:token[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict['conceptMentions']['string']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
