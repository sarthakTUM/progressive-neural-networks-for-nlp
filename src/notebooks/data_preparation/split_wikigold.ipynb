{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(filepath):\n",
    "    all_toks = []\n",
    "    all_cats = []\n",
    "    sents = []\n",
    "    with io.open(filepath, encoding='ISO-8859-1') as ip:\n",
    "        sent = []\n",
    "        for line in ip:\n",
    "            if line == '\\n':\n",
    "                sents.append(sent)\n",
    "                sent = []\n",
    "            else:\n",
    "                line = line.strip()\n",
    "                parts = line.split()\n",
    "                #print(parts)\n",
    "                token = parts[0]\n",
    "                if not len(parts)>1:\n",
    "                    print(line)\n",
    "                cat = line.split()[1]\n",
    "                all_toks.append(token)\n",
    "                all_cats.append(cat)\n",
    "                sent.append((token, cat))\n",
    "    return sents, all_toks, all_cats\n",
    "\n",
    "def get_tags_ents(all_cats):\n",
    "    tags = []\n",
    "    ents = []\n",
    "    for cat in set(all_cats):\n",
    "        parts = cat.split('-')\n",
    "        tags.append(parts[0])\n",
    "        if len(parts) > 1:\n",
    "            ents.append(parts[1])\n",
    "        \n",
    "    return set(tags), set(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train file...\n"
     ]
    }
   ],
   "source": [
    "print('processing train file...')\n",
    "all_sents, all_all_toks, all_all_cats = read_conll('../../../resources/data/NER/wikigold/data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_prop = 0.2\n",
    "test_size = int(test_prop*len(all_sents))\n",
    "valid_prop = 0.1\n",
    "valid_size = int(valid_prop*len(all_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_indices = random.sample(range(len(all_sents)), test_size)\n",
    "test_sents = [all_sents[idx] for idx in random_test_indices]\n",
    "train_sents = np.delete(all_sents, random_test_indices).tolist()\n",
    "random_valid_indices = random.sample(range(len(train_sents)), valid_size)\n",
    "valid_sents = [train_sents[idx] for idx in random_valid_indices]\n",
    "train_sents = np.delete(train_sents, random_valid_indices).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train:  1187\n",
      "len valid:  169\n",
      "len test:  339\n"
     ]
    }
   ],
   "source": [
    "print('len train: ', len(train_sents))\n",
    "print('len valid: ', len(valid_sents))\n",
    "print('len test: ', len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conll(filepath, data):\n",
    "    print('starting writing..')\n",
    "    with io.open(filepath, 'w', encoding='utf-8') as fl:\n",
    "        fl.write('-DOCSTART-\\n')\n",
    "        for sent in data:\n",
    "            fl.write('\\n')\n",
    "            for tup in sent:\n",
    "                fl.write(tup[0] + ' ' + tup[1] + '\\n')\n",
    "    print('finished writing..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting writing..\n",
      "finished writing..\n"
     ]
    }
   ],
   "source": [
    "write_conll('../../../resources/data/NER/wikigold/train.txt', train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting writing..\n",
      "finished writing..\n"
     ]
    }
   ],
   "source": [
    "write_conll('../../../resources/data/NER/wikigold/valid.txt', valid_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting writing..\n",
      "finished writing..\n"
     ]
    }
   ],
   "source": [
    "write_conll('../../../resources/data/NER/wikigold/test.txt', test_sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
