{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_path = '../../../'\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch\n",
    "from src.tc import utils\n",
    "from src.ner.encoder import CharEncoder, ClassEncoder, WordEncoder\n",
    "from src.tc.model.net import CNNTC\n",
    "from src.tc.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_path, 'src/tc/data/sst_binary')\n",
    "model_dir = os.path.join(root_path, 'src/tc/experiments/sst_binary_testjupyter')\n",
    "restore_file = 'best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. set the device to train on\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the parameters from json file\n",
    "network_params = os.path.join(model_dir, 'params.json')\n",
    "assert os.path.isfile(network_params), \"No json configuration file found at {}\".format(network_params)\n",
    "params = utils.Params(network_params)\n",
    "params.cuda = torch.cuda.is_available() # use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Set the random seed for reproducible experiments\n",
    "torch.manual_seed(230)\n",
    "if params.cuda: torch.cuda.manual_seed(230)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set the logger\n",
    "utils.set_logger(os.path.join(model_dir, 'train.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the datasets...\n",
      "- done.\n",
      "test size: 1821\n"
     ]
    }
   ],
   "source": [
    "# 5. Create the input data pipeline\n",
    "logging.info(\"Loading the datasets...\")\n",
    "# 5.1 specify features\n",
    "from collections import OrderedDict\n",
    "data_encoder = OrderedDict()\n",
    "label_encoder = OrderedDict()\n",
    "data_encoder[CharEncoder.FEATURE_NAME] = CharEncoder(os.path.join(data_dir, 'feats'))\n",
    "data_encoder[WordEncoder.FEATURE_NAME] = WordEncoder(os.path.join(data_dir, 'feats'))\n",
    "label_encoder[ClassEncoder.FEATURE_NAME] = ClassEncoder(os.path.join(data_dir, 'feats'))\n",
    "\n",
    "# 5.2 load data\n",
    "data_loader = DataLoader(params, data_dir, data_encoder, label_encoder)\n",
    "data = data_loader.load_data(['test'], data_dir)\n",
    "test_data = data['test']\n",
    "test_data_iterator = data_loader.batch_iterator(test_data, params, shuffle=False)\n",
    "\n",
    "# 5.3 specify the train and val dataset sizes\n",
    "params.test_size = test_data['size']\n",
    "logging.info(\"- done.\")\n",
    "logging.info('test size: {}'.format(params.test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Modeling\n",
    "# 6.1 Define the model\n",
    "model = CNNTC(  params=params,\n",
    "                char_vocab_length=data_encoder[CharEncoder.FEATURE_NAME].vocab_length,\n",
    "                num_tags=label_encoder[ClassEncoder.FEATURE_NAME].num_tags,\n",
    "                pretrained_word_vecs=torch.from_numpy(data_encoder[WordEncoder.FEATURE_NAME].vectors),\n",
    "                dropout=params.dropout,\n",
    "                decoder_type=params.decoder,\n",
    "                bidirectional=params.rnn_bidirectional,\n",
    "                freeze_embeddings=params.freeze_wordembeddings).to(device).float()\n",
    "# 6.2 fetch metrics\n",
    "from src.ner.evaluation import accuracy_score\n",
    "metrics = {'accuracy': accuracy_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.812 ; loss: 0.413\n"
     ]
    }
   ],
   "source": [
    "utils.load_checkpoint(os.path.join(model_dir, restore_file + '.pth'), model)\n",
    "\n",
    "# Evaluate\n",
    "from src.tc.evaluate import evaluate\n",
    "num_steps = (params.test_size + 1) // params.batch_size\n",
    "test_metrics = evaluate(model,\n",
    "                        test_data_iterator,\n",
    "                        metrics,\n",
    "                        params,\n",
    "                        num_steps,\n",
    "                        label_encoder,\n",
    "                        data_encoder)\n",
    "save_path = os.path.join(model_dir, \"metrics_test_{}.json\".format(restore_file))\n",
    "utils.save_dict_to_json(test_metrics, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
