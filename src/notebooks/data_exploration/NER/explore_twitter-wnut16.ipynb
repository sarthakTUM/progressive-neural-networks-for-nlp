{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(filepath):\n",
    "    all_toks = []\n",
    "    all_cats = []\n",
    "    sents = []\n",
    "    with io.open(filepath, encoding='utf-8') as ip:\n",
    "        sent = []\n",
    "        for line in ip:\n",
    "            if line == '\\n':\n",
    "                sents.append(sent)\n",
    "                sent = []\n",
    "            else:\n",
    "                line = line.strip()\n",
    "                token = line.split('\\t')[0]\n",
    "                cat = line.split('\\t')[1]\n",
    "                all_toks.append(token)\n",
    "                all_cats.append(cat)\n",
    "                sent.append((token, cat))\n",
    "    return sents, all_toks, all_cats\n",
    "\n",
    "def get_tags_ents(all_cats):\n",
    "    tags = []\n",
    "    ents = []\n",
    "    for cat in set(all_cats):\n",
    "        parts = cat.split('-')\n",
    "        tags.append(parts[0])\n",
    "        if len(parts) > 1:\n",
    "            ents.append(parts[1])\n",
    "        \n",
    "    return set(tags), set(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train file...\n",
      "processing validation file...\n",
      "processing testing file...\n"
     ]
    }
   ],
   "source": [
    "print('processing train file...')\n",
    "train_sents, train_all_toks, train_all_cats = read_conll('../../../resources/data/NER/twitter_wnut16/train')\n",
    "\n",
    "print('processing validation file...')\n",
    "valid_sents, valid_all_toks, valid_all_cats = read_conll('../../../resources/data/NER/twitter_wnut16/dev')\n",
    "\n",
    "print('processing testing file...')\n",
    "test_sents, test_all_toks, test_all_cats = read_conll('../../../resources/data/NER/twitter_wnut16/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sentences:  2394\n",
      "# validation sentences:  1000\n",
      "# testing sentences:  3856\n"
     ]
    }
   ],
   "source": [
    "print('# training sentences: ', len(train_sents))\n",
    "print('# validation sentences: ', len(valid_sents))\n",
    "print('# testing sentences: ', len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique training tokens:  10586\n",
      "# unique_validation tokens:  6255\n",
      "# unique_testing tokens:  18320\n"
     ]
    }
   ],
   "source": [
    "print('# unique training tokens: ', len(set(train_all_toks)))\n",
    "print('# unique_validation tokens: ', len(set(valid_all_toks)))\n",
    "print('# unique_testing tokens: ', len(set(test_all_toks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training categories:  21\n",
      "# validation categories:  20\n",
      "# testing categories:  21\n"
     ]
    }
   ],
   "source": [
    "print('# training categories: ', len(set(train_all_cats)))\n",
    "print('# validation categories: ', len(set(valid_all_cats)))\n",
    "print('# testing categories: ', len(set(test_all_cats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training tags, entities:  {'O', 'B', 'I'} {'sportsteam', 'movie', 'person', 'musicartist', 'geo', 'tvshow', 'other', 'company', 'facility', 'product'} 10\n",
      "validation tags, entities:  {'O', 'B', 'I'} {'sportsteam', 'movie', 'person', 'musicartist', 'geo', 'tvshow', 'company', 'facility', 'other', 'product'} 10\n",
      "training tags, entities:  {'O', 'B', 'I'} {'sportsteam', 'movie', 'person', 'musicartist', 'geo', 'tvshow', 'other', 'company', 'facility', 'product'} 10\n"
     ]
    }
   ],
   "source": [
    "train_tags, train_ents = get_tags_ents(train_all_cats)\n",
    "print('training tags, entities: ', train_tags, train_ents, len(train_ents))\n",
    "\n",
    "valid_tags, valid_ents = get_tags_ents(valid_all_cats)\n",
    "print('validation tags, entities: ', valid_tags, valid_ents, len(valid_ents))\n",
    "\n",
    "test_tags, test_ents = get_tags_ents(test_all_cats)\n",
    "print('training tags, entities: ', test_tags, test_ents, len(test_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training distribution\n",
      "Counter({'O': 44007, 'B-person': 449, 'I-other': 320, 'B-geo-loc': 276, 'B-other': 225, 'I-person': 215, 'B-company': 171, 'I-facility': 105, 'B-facility': 104, 'B-product': 97, 'I-product': 80, 'I-musicartist': 61, 'B-musicartist': 55, 'B-sportsteam': 51, 'I-geo-loc': 49, 'I-movie': 46, 'I-company': 36, 'B-movie': 34, 'B-tvshow': 34, 'I-tvshow': 31, 'I-sportsteam': 23})\n",
      "\n",
      "\n",
      "validation distribution\n",
      "Counter({'O': 15133, 'B-person': 171, 'B-other': 132, 'I-product': 121, 'B-geo-loc': 116, 'I-other': 97, 'I-person': 95, 'B-sportsteam': 70, 'I-geo-loc': 42, 'B-musicartist': 41, 'I-facility': 39, 'B-company': 39, 'B-facility': 38, 'B-product': 37, 'I-musicartist': 35, 'B-movie': 15, 'I-movie': 15, 'I-sportsteam': 13, 'I-company': 10, 'B-tvshow': 2})\n",
      "\n",
      "\n",
      "testing distribution\n",
      "Counter({'O': 55953, 'B-geo-loc': 882, 'B-company': 621, 'B-other': 584, 'I-other': 556, 'I-product': 500, 'B-person': 482, 'I-facility': 366, 'I-person': 300, 'I-company': 265, 'B-facility': 253, 'B-product': 246, 'I-geo-loc': 219, 'B-musicartist': 191, 'B-sportsteam': 147, 'I-musicartist': 140, 'I-movie': 48, 'I-sportsteam': 48, 'I-tvshow': 40, 'B-movie': 34, 'B-tvshow': 33})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('training distribution')\n",
    "print(Counter(train_all_cats))\n",
    "print('\\n')\n",
    "\n",
    "print('validation distribution')\n",
    "print(Counter(valid_all_cats))\n",
    "print('\\n')\n",
    "\n",
    "print('testing distribution')\n",
    "print(Counter(test_all_cats))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
