{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(filepath):\n",
    "    all_toks = []\n",
    "    all_cats = []\n",
    "    sents = []\n",
    "    with io.open(filepath, encoding='utf-8') as ip:\n",
    "        sent = []\n",
    "        for line in ip:\n",
    "            if line == '-DOCSTART-\\n':\n",
    "                continue\n",
    "            if line == '\\n':\n",
    "                sents.append(sent)\n",
    "                sent = []\n",
    "            else:\n",
    "                line = line.strip()\n",
    "                parts = line.split()\n",
    "                #print(parts)\n",
    "                token = parts[0]\n",
    "                if not len(parts)>1:\n",
    "                    print(line)\n",
    "                cat = line.split()[1]\n",
    "                all_toks.append(token)\n",
    "                all_cats.append(cat)\n",
    "                sent.append((token, cat))\n",
    "    return sents, all_toks, all_cats\n",
    "\n",
    "def get_tags_ents(all_cats):\n",
    "    tags = []\n",
    "    ents = []\n",
    "    for cat in set(all_cats):\n",
    "        parts = cat.split('-')\n",
    "        tags.append(parts[0])\n",
    "        if len(parts) > 1:\n",
    "            ents.append(parts[1])\n",
    "        \n",
    "    return set(tags), set(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train file...\n",
      "processing validation file...\n",
      "processing testing file...\n"
     ]
    }
   ],
   "source": [
    "print('processing train file...')\n",
    "train_sents, train_all_toks, train_all_cats = read_conll('../../../resources/data/NER/wikigold/train.txt')\n",
    "\n",
    "print('processing validation file...')\n",
    "valid_sents, valid_all_toks, valid_all_cats = read_conll('../../../resources/data/NER/wikigold/valid.txt')\n",
    "\n",
    "print('processing testing file...')\n",
    "test_sents, test_all_toks, test_all_cats = read_conll('../../../resources/data/NER/wikigold/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sentences:  1187\n",
      "# validation sentences:  169\n",
      "# testing sentences:  339\n"
     ]
    }
   ],
   "source": [
    "print('# training sentences: ', len(train_sents))\n",
    "print('# validation sentences: ', len(valid_sents))\n",
    "print('# testing sentences: ', len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique training tokens:  6877\n",
      "# unique_validation tokens:  1801\n",
      "# unique_testing tokens:  2829\n"
     ]
    }
   ],
   "source": [
    "print('# unique training tokens: ', len(set(train_all_toks)))\n",
    "print('# unique_validation tokens: ', len(set(valid_all_toks)))\n",
    "print('# unique_testing tokens: ', len(set(test_all_toks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training categories:  16\n",
      "# validation categories:  11\n",
      "# testing categories:  11\n"
     ]
    }
   ],
   "source": [
    "print('# training categories: ', len(set(train_all_cats)))\n",
    "print('# validation categories: ', len(set(valid_all_cats)))\n",
    "print('# testing categories: ', len(set(test_all_cats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training tags, entities:  {'Â\\x84ski', 'Â\\x82awa', 'B', 'Â\\x82aw', 'Â\\x9fti', 'Ã\\x8eÂ³Ã\\x8eÂºÃ\\x8eÂ¿Ã\\x8eÂ¹Ã\\x8eÂ½Ã\\x8fÂ\\x89Ã\\x8eÂ½Ã\\x8eÂ¹Ã\\x8fÂ\\x8eÃ\\x8eÂ½', 'O', 'ibenik', 't', 'I'} {'ORG', 'Knin', 'MISC', 'PER', 'LOC'} 5\n",
      "validation tags, entities:  {'Â\\x84', 'B', 'I', 'O', 'Â\\x81Ã\\x84Â\\x99czyca'} {'MISC', 'ORG', 'LOC', 'PER'} 4\n",
      "training tags, entities:  {'Â\\x84', 'Â\\x9fescu', 'B', 'O', 'I'} {'MISC', 'ORG', 'LOC', 'PER'} 4\n"
     ]
    }
   ],
   "source": [
    "train_tags, train_ents = get_tags_ents(train_all_cats)\n",
    "print('training tags, entities: ', train_tags, train_ents, len(train_ents))\n",
    "\n",
    "valid_tags, valid_ents = get_tags_ents(valid_all_cats)\n",
    "print('validation tags, entities: ', valid_tags, valid_ents, len(valid_ents))\n",
    "\n",
    "test_tags, test_ents = get_tags_ents(test_all_cats)\n",
    "print('training tags, entities: ', test_tags, test_ents, len(test_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training distribution\n",
      "Counter({'O': 22486, 'I-ORG': 768, 'B-LOC': 684, 'B-PER': 644, 'B-ORG': 626, 'I-PER': 493, 'B-MISC': 482, 'I-MISC': 471, 'I-LOC': 295, 'Â\\x82aw': 2, 'Â\\x82awa': 1, 'Â\\x84ski': 1, 't': 1, 'Ã\\x8eÂ³Ã\\x8eÂºÃ\\x8eÂ¿Ã\\x8eÂ¹Ã\\x8eÂ½Ã\\x8fÂ\\x89Ã\\x8eÂ½Ã\\x8eÂ¹Ã\\x8fÂ\\x8eÃ\\x8eÂ½': 1, 'Â\\x9fti': 1, 'ibenik-Knin': 1})\n",
      "\n",
      "\n",
      "validation distribution\n",
      "Counter({'O': 3593, 'B-LOC': 107, 'I-ORG': 97, 'B-PER': 91, 'B-ORG': 90, 'I-PER': 73, 'B-MISC': 66, 'I-MISC': 63, 'I-LOC': 60, 'Â\\x81Ã\\x84Â\\x99czyca': 1, 'Â\\x84': 1})\n",
      "\n",
      "\n",
      "testing distribution\n",
      "Counter({'O': 6491, 'B-LOC': 217, 'I-ORG': 199, 'B-PER': 193, 'B-ORG': 176, 'B-MISC': 157, 'I-MISC': 152, 'I-PER': 133, 'I-LOC': 80, 'Â\\x84': 1, 'Â\\x9fescu': 1})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('training distribution')\n",
    "print(Counter(train_all_cats))\n",
    "print('\\n')\n",
    "\n",
    "print('validation distribution')\n",
    "print(Counter(valid_all_cats))\n",
    "print('\\n')\n",
    "\n",
    "print('testing distribution')\n",
    "print(Counter(test_all_cats))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
