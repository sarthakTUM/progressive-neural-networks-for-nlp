{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(filepath):\n",
    "    all_toks = []\n",
    "    all_cats = []\n",
    "    sents = []\n",
    "    with io.open(filepath, encoding='utf-8') as ip:\n",
    "        sent = []\n",
    "        for line in ip:\n",
    "            if line == '\\n':\n",
    "                sents.append(sent)\n",
    "                sent = []\n",
    "            else:\n",
    "                line = line.strip()\n",
    "                token = line.split('\\t')[0]\n",
    "                cat = line.split('\\t')[1]\n",
    "                all_toks.append(token)\n",
    "                all_cats.append(cat)\n",
    "                sent.append((token, cat))\n",
    "    return sents, all_toks, all_cats\n",
    "\n",
    "def get_tags_ents(all_cats):\n",
    "    tags = []\n",
    "    ents = []\n",
    "    for cat in set(all_cats):\n",
    "        parts = cat.split('-')\n",
    "        tags.append(parts[0])\n",
    "        if len(parts) > 1:\n",
    "            ents.append(parts[1])\n",
    "        \n",
    "    return set(tags), set(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train file...\n",
      "processing testing file...\n"
     ]
    }
   ],
   "source": [
    "print('processing train file...')\n",
    "train_sents, train_all_toks, train_all_cats = read_conll('../../../resources/data/NER/biomedical/train.iob2')\n",
    "\n",
    "print('processing testing file...')\n",
    "test_sents, test_all_toks, test_all_cats = read_conll('../../../resources/data/NER/biomedical/test.iob2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "valid_prop = 0.1\n",
    "valid_size = int(valid_prop*len(train_sents))\n",
    "random_indices = random.sample(range(len(train_sents)), valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sents = [train_sents[idx] for idx in random_indices]\n",
    "train_sents = np.delete(train_sents, random_indices).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation sents:  1854\n",
      "training sentences:  16692\n"
     ]
    }
   ],
   "source": [
    "print('validation sents: ', len(valid_sents))\n",
    "print('training sentences: ', len(train_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conll(filepath, data):\n",
    "    print('starting writing..')\n",
    "    with io.open(filepath, 'w', encoding='utf-8') as fl:\n",
    "        fl.write('-DOCSTART-\\n')\n",
    "        for sent in data:\n",
    "            fl.write('\\n')\n",
    "            for tup in sent:\n",
    "                fl.write(tup[0] + '\\t' + tup[1] + '\\n')\n",
    "    print('finished writing..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting writing..\n",
      "finished writing..\n"
     ]
    }
   ],
   "source": [
    "write_conll('../../../resources/data/NER/biomedical/train.iob2', train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting writing..\n",
      "finished writing..\n"
     ]
    }
   ],
   "source": [
    "write_conll('../../../resources/data/NER/biomedical/valid.iob2', valid_sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
