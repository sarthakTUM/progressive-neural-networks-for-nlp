{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a network for Named Entity Recognition with architecture mentioned in [].\n",
    "\n",
    "How to run:\n",
    "1. Specify the data_dir. The directory should contain the train, val, and test folders, along with the 'feats' folder obtained through feat.ipynb.\n",
    "2. specify the model directory. The directory needs to be created manually. It should contain a params.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_path = '../../../'\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm import trange\n",
    "from src.ner import utils\n",
    "from src.ner.model.data_loader import DataLoader\n",
    "from src.ner.evaluate import evaluate\n",
    "from src.booster.progressive_encoder import CharEncoder, EntityEncoder, WordEncoder\n",
    "from src.booster.progNN.net import LSTMCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_path, 'src/ner/data/bc5cdr_iobes_id')\n",
    "model_dir = os.path.join(root_path, 'src/ner/experiments/test/bc5cdr_testjupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. set the device to train on\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the parameters from json file\n",
    "network_params = os.path.join(model_dir, 'params.json')\n",
    "assert os.path.isfile(network_params), \"No json configuration file found at {}\".format(network_params)\n",
    "params = utils.Params(network_params)\n",
    "params.cuda = torch.cuda.is_available() # use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Set the random seed for reproducible experiments\n",
    "torch.manual_seed(230)\n",
    "if params.cuda: torch.cuda.manual_seed(230)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set the logger\n",
    "utils.set_logger(os.path.join(model_dir, 'train.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the datasets...\n",
      "- done.\n",
      "train size: 4559\n",
      "val size: 4580\n",
      "test size: 4796\n"
     ]
    }
   ],
   "source": [
    "# 5. Create the input data pipeline\n",
    "logging.info(\"Loading the datasets...\")\n",
    "\n",
    "from collections import OrderedDict\n",
    "data_encoder = OrderedDict()\n",
    "label_encoder = OrderedDict()\n",
    "data_encoder[CharEncoder.FEATURE_NAME] = CharEncoder(os.path.join(data_dir, 'feats'))\n",
    "data_encoder[WordEncoder.FEATURE_NAME] = WordEncoder(os.path.join(data_dir, 'feats'),\n",
    "                                                     dim=params.embedding_dim)\n",
    "label_encoder[EntityEncoder.FEATURE_NAME] = EntityEncoder(os.path.join(data_dir, 'feats'))\n",
    "\n",
    "# 5.2 load data\n",
    "data_loader = DataLoader(params, data_dir, data_encoder, label_encoder)\n",
    "data = data_loader.load_data(['train', 'val', 'test'], data_dir)\n",
    "train_data = data['train']\n",
    "val_data = data['val']\n",
    "test_data = data['test']\n",
    "\n",
    "# 5.3 specify the train and val dataset sizes\n",
    "params.train_size = train_data['size']\n",
    "params.val_size = val_data['size']\n",
    "params.test_size = test_data['size']\n",
    "logging.info(\"- done.\")\n",
    "logging.info('train size: {}'.format(params.train_size))\n",
    "logging.info('val size: {}'.format(params.val_size))\n",
    "logging.info('test size: {}'.format(params.test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params:  40435014\n",
      "total trainable params:  434670\n"
     ]
    }
   ],
   "source": [
    "model = LSTMCRF(params=params,\n",
    "                char_vocab_length=data_encoder[CharEncoder.FEATURE_NAME].vocab_length,\n",
    "                num_tags=label_encoder[EntityEncoder.FEATURE_NAME].num_tags,\n",
    "                pretrained_word_vecs=torch.from_numpy(data_encoder[WordEncoder.FEATURE_NAME].vectors),\n",
    "                dropout=params.dropout,\n",
    "                decoder_type=params.decoder,\n",
    "                bidirectional=params.rnn_bidirectional,\n",
    "                freeze_embeddings=params.freeze_wordembeddings).to(device).float()\n",
    "model_total_params = sum(p.numel() for p in model.parameters())\n",
    "model_total_trainable_params = sum(p.numel() for p in filter(lambda p: p.requires_grad,\n",
    "                                                             model.parameters()))\n",
    "print('total params: ', model_total_params)\n",
    "print('total trainable params: ', model_total_trainable_params)\n",
    "optimizer = optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                      lr=params.learning_rate,\n",
    "                      momentum=params.momentum)\n",
    "\n",
    "# 6.2 fetch loss function and metrics\n",
    "from src.ner.evaluation import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "metrics = {'accuracy': accuracy_score,\n",
    "           'f1_score': f1_score,  # micro F1 score\n",
    "           'precision_score': precision_score,\n",
    "           'recall_score': recall_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 2 epoch(s)\n",
      "Epoch 1/2\n",
      "Learning Rate : [0.015]\n",
      "100%|███████████████████████████████████████████████████████████████████| 456/456 [00:36<00:00, 13.02it/s, loss=36.860]\n",
      "- Train metrics: accuracy: 0.934 ; f1_score: 0.705 ; precision_score: 0.696 ; recall_score: 0.714 ; loss: 39.655\n",
      "- Val Eval metrics : accuracy: 0.947 ; f1_score: 0.740 ; precision_score: 0.671 ; recall_score: 0.825 ; loss: 25.250\n",
      "- Test Eval metrics : accuracy: 0.946 ; f1_score: 0.720 ; precision_score: 0.651 ; recall_score: 0.805 ; loss: 25.685\n",
      "- Found new best F1 score\n",
      "Epoch 2/2\n",
      "Learning Rate : [0.014285714285714284]\n",
      "100%|███████████████████████████████████████████████████████████████████| 456/456 [00:36<00:00, 12.80it/s, loss=30.773]\n",
      "- Train metrics: accuracy: 0.964 ; f1_score: 0.839 ; precision_score: 0.817 ; recall_score: 0.862 ; loss: 31.079\n",
      "- Val Eval metrics : accuracy: 0.952 ; f1_score: 0.771 ; precision_score: 0.706 ; recall_score: 0.848 ; loss: 22.590\n",
      "- Test Eval metrics : accuracy: 0.951 ; f1_score: 0.749 ; precision_score: 0.690 ; recall_score: 0.821 ; loss: 23.096\n",
      "- Found new best F1 score\n"
     ]
    }
   ],
   "source": [
    "# 7. Train the model\n",
    "\"\"\"\n",
    "params: restore_file: specify the model path to finetune\n",
    "params: save_model: Boolean, to save model at the end of the epoch or not. Model is saved for the best F1 score on validation set\n",
    "params: eval: whether to run the evaluation on the validation set or not.\n",
    "\"\"\"\n",
    "from src.ner.train_new import train_and_evaluate\n",
    "logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "end_epoch = train_and_evaluate(model=model,\n",
    "                               data_loader=data_loader,\n",
    "                               train_data=train_data,\n",
    "                               val_data=val_data,\n",
    "                               test_data=test_data,\n",
    "                               optimizer=optimizer,\n",
    "                               metrics=metrics,\n",
    "                               params=params,\n",
    "                               model_dir=model_dir,\n",
    "                               data_encoder=data_encoder,\n",
    "                               label_encoder=label_encoder,\n",
    "                               restore_file=None,\n",
    "                               save_model=True,\n",
    "                               eval=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
